{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Large Language Model in the GenAI Hub of SAP AI Core on BTP\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "- Have [python](https://www.python.org/downloads/) installed\n",
    "- Create an instance of SAP AI Core in your BTP sub-account: [documentation](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/initial-setup?locale=en-US)\n",
    "- Find information about available LLM's in [SAP Note 3437766](https://me.sap.com/notes/3437766) \n",
    "- Optionally, have the [Cloud Foundry CLI installed](https://docs.cloudfoundry.org/cf-cli/install-go-cli.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8963.94s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ai_core_sdk in ./.venv/lib/python3.11/site-packages (2.4.12)\n",
      "Requirement already satisfied: ai-api-client-sdk==2.4.0 in ./.venv/lib/python3.11/site-packages (from ai_core_sdk) (2.4.0)\n",
      "Requirement already satisfied: click~=8.1 in ./.venv/lib/python3.11/site-packages (from ai_core_sdk) (8.1.7)\n",
      "Requirement already satisfied: aenum~=3.1 in ./.venv/lib/python3.11/site-packages (from ai-api-client-sdk==2.4.0->ai_core_sdk) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in ./.venv/lib/python3.11/site-packages (from ai-api-client-sdk==2.4.0->ai_core_sdk) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0 in ./.venv/lib/python3.11/site-packages (from ai-api-client-sdk==2.4.0->ai_core_sdk) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk==2.4.0->ai_core_sdk) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk==2.4.0->ai_core_sdk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk==2.4.0->ai_core_sdk) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk==2.4.0->ai_core_sdk) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the AI Core SDK with pip\n",
    "\n",
    "%pip install ai_core_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.ai.intprod-eu12.eu-central-1.aws.ml.hana.ondemand.com\n"
     ]
    }
   ],
   "source": [
    "# In your working directory, log on to BTP with cf logon\n",
    "# Download the credentials of your AICore instance with cf service-key <service-name> <key-name> > key.json\n",
    "# Remove the first line of the key.json file\n",
    "# Alternatively, create and download a service key in the BTP cockpit \n",
    "\n",
    "import json\n",
    "\n",
    "with open('key.json') as f:\n",
    "    btp_key = json.load(f).get('credentials')   # when using cf service-key\n",
    "    # btp_key = json.load(f)                    # when using a downloaded service key from BTP cockpit\n",
    "\n",
    "print(btp_key[\"serviceurls\"][\"AI_API_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AI Core SDK\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "\n",
    "# Create Connection using credentials from downloaded key.json\n",
    "ai_core_client = AICoreV2Client(\n",
    "    base_url = btp_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\", # The present SAP AI Core API version is 2\n",
    "    auth_url=  btp_key[\"url\"] + \"/oauth/token\", # Suffix to add\n",
    "    client_id = btp_key[\"clientid\"],\n",
    "    client_secret = btp_key[\"clientsecret\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "# Query existing resource groups. It is expected that group \"default\" is present\n",
    "response = ai_core_client.resource_groups.query()\n",
    "\n",
    "for rg in response.resources:\n",
    "    print(rg.resource_group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable: aicore-ibm - supportedModels: ibm--granite-13b-chat\n",
      "Executable: aicore-ibm - None\n",
      "Executable: aicore-mistralai - supportedModels: mistralai--mistral-large-instruct\n",
      "Executable: aicore-mistralai - None\n",
      "Executable: aicore-nvidia - supportedModels: NV-Rerank-QA-Mistral-4B, NV-Embed-QA\n",
      "Executable: aicore-nvidia - None\n",
      "Executable: aicore-opensource - None\n",
      "Executable: aicore-opensource - None\n",
      "Executable: aws-bedrock - supportedModels: amazon--titan-text-express, amazon--titan-text-lite, amazon--titan-embed-text, amazon--titan-image-generator, anthropic--claude-3-haiku, anthropic--claude-3-opus, anthropic--claude-3-sonnet, anthropic--claude-3.5-sonnet\n",
      "Executable: aws-bedrock - None\n",
      "Executable: azure-openai - supportedModels: gpt-35-turbo, gpt-35-turbo-0125, gpt-35-turbo-16k, gpt-4o, gpt-4, gpt-4-32k, text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large, dall-e-3, gpt-4o-mini\n",
      "Executable: azure-openai - None\n",
      "Executable: gcp-vertexai - supportedModels: text-bison, chat-bison, textembedding-gecko-multilingual, textembedding-gecko, gemini-1.0-pro, gemini-1.5-pro, gemini-1.5-flash\n",
      "Executable: gcp-vertexai - None\n"
     ]
    }
   ],
   "source": [
    "# Find available models and their corresponding exectuables\n",
    "# Alternatively, find this information in SAP Note 3437766 - https://me.sap.com/notes/3437766\n",
    "\n",
    "exc = ai_core_client.executable.query(resource_group=\"default\", scenario_id=\"foundation-models\")\n",
    "\n",
    "for e in exc.resources:\n",
    "    p = e.parameters\n",
    "    for i in p: \n",
    "        print (f\"Executable: {e.id} - {i.description}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Configuration for OpenAI gpt-4o\n",
    "\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "\n",
    "model_to_deploy = \"gpt-4o\"\n",
    "executable_id = \"azure-openai\"\n",
    "\n",
    "pb1 = ParameterBinding(key=\"modelName\", value=model_to_deploy)\n",
    "pb2 = ParameterBinding(key=\"modelVersion\", value=\"latest\")\n",
    "\n",
    "ai_core_client.configuration.create( name=model_to_deploy, executable_id=executable_id, scenario_id=\"foundation-models\",resource_group=\"default\", parameter_bindings=[pb1, pb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ID: fb1a73a5-8842-4e5f-be18-e8bc5911790d, Executable ID: azure-openai, Name: gpt-35-turbo, Param0: gpt-35-turbo, Param1: latest\n",
      "Configuration ID: 53a15731-338e-4873-ba66-cbcc0d45e7e6, Executable ID: aicore-mistralai, Name: mistral, Param0: mistralai--mistral-large-instruct, Param1: latest\n",
      "Configuration ID: fb4f93a9-a998-4079-9a7c-dfb6cf3ad428, Executable ID: azure-openai, Name: gpt-4o-mini, Param0: gpt-4o-mini, Param1: latest\n",
      "Configuration ID: ce93b5ef-9e1f-46c5-a5de-497667d1e63b, Executable ID: aws-bedrock, Name: claude, Param0: anthropic--claude-3.5-sonnet, Param1: latest\n",
      "Configuration ID: 4be0f740-3d39-4522-aa90-0cb2061c4e1d, Executable ID: azure-openai, Name: gpt-40, Param0: gpt-4o, Param1: latest\n"
     ]
    }
   ],
   "source": [
    "# Query existing Configurations\n",
    "confs = ai_core_client.configuration.query(scenario_id=\"foundation-models\", resource_group=\"default\")\n",
    "\n",
    "for resource in confs.resources:\n",
    "    print(f\"Configuration ID: {resource.id}, Executable ID: {resource.executable_id}, Name: {resource.name}, Param0: {resource.parameter_bindings[0].value}, Param1: {resource.parameter_bindings[1].value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ai_api_client_sdk.models.deployment_create_response.DeploymentCreateResponse at 0x10ddaded0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention: make sure to use the correct configuration id which corresponds to the model you want to deploy\n",
    "\n",
    "conf_id = \"4be0f740-3d39-4522-aa90-0cb2061c4e1d\"\n",
    "\n",
    "# Create a deployment for the configuration\n",
    "ai_core_client.deployment.create(configuration_id=conf_id, resource_group=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources: [{Deployment id: d0800c3392042c93}, {Deployment id: dab3e0a7598c5ebd}], Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Optional: Find existing deployments for a configuration\n",
    "\n",
    "deps = ai_core_client.deployment.query(resource_group=\"default\", configuration_id=conf_id)\n",
    "\n",
    "print(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d0800c3392042c93\n",
      "gpt-4o\n",
      "latest\n",
      "dab3e0a7598c5ebd\n",
      "gpt-4o\n",
      "latest\n"
     ]
    }
   ],
   "source": [
    "# Optional: Get details of a deployment\n",
    "\n",
    "for dep in deps.resources:\n",
    "    print(dep.id)\n",
    "    dep_detail = ai_core_client.deployment.get(deployment_id=dep.id, resource_group=\"default\")\n",
    "    print(dep_detail.details['resources']['backend_details']['model']['name'])\n",
    "    print(dep_detail.details['resources']['backend_details']['model']['version'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
